{"componentChunkName":"component---src-templates-project-template-tsx","path":"/sample-experiment/","result":{"data":{"markdownRemark":{"frontmatter":{"title":"Interactive Particle System","description":"An interactive particle system that responds to mouse movement and music, creating a visually engaging experience.","url":null,"category":null,"tags":null},"html":"<h1>Interactive Particle System</h1>\n<h2>Overview</h2>\n<p>This experiment creates an interactive particle system that responds to both mouse movement and music. The particles dynamically react to audio frequencies, creating a visually engaging experience that bridges visual and auditory senses.</p>\n<h2>Technical Details</h2>\n<p>The experiment uses Three.js for rendering, the Web Audio API for audio analysis, and custom GLSL shaders for particle effects. The system can handle up to 100,000 particles with smooth performance on modern browsers.</p>\n<h2>Code Sample</h2>\n<pre><code class=\"language-javascript\">// Create particle system\nconst particleSystem = new THREE.Points(\n  new THREE.BufferGeometry(),\n  new THREE.ShaderMaterial({\n    uniforms: {\n      uTime: { value: 0 },\n      uAudioFrequencies: { value: new Float32Array(128) },\n      uMousePosition: { value: new THREE.Vector2() }\n    },\n    vertexShader: `\n      uniform float uTime;\n      uniform float uAudioFrequencies[128];\n      uniform vec2 uMousePosition;\n      \n      attribute float audioIndex;\n      \n      varying vec3 vColor;\n      \n      void main() {\n        // Get audio frequency for this particle\n        float freqValue = uAudioFrequencies[int(audioIndex)];\n        \n        // Calculate position based on audio and mouse\n        vec3 pos = position;\n        pos.x += sin(uTime * 0.5 + position.z) * freqValue * 0.2;\n        pos.y += cos(uTime * 0.5 + position.x) * freqValue * 0.2;\n        \n        // Mouse influence\n        float distToMouse = distance(uMousePosition, vec2(pos.x, pos.y));\n        float mouseInfluence = smoothstep(1.0, 0.0, distToMouse / 2.0);\n        pos.z += mouseInfluence * freqValue * 2.0;\n        \n        // Set position and color\n        gl_Position = projectionMatrix * modelViewMatrix * vec4(pos, 1.0);\n        gl_PointSize = freqValue * 8.0 + 1.0;\n        \n        vColor = vec3(freqValue * 0.8, mouseInfluence * 0.7, 0.6);\n      }\n    `,\n    fragmentShader: `\n      varying vec3 vColor;\n      \n      void main() {\n        // Draw a circle for each particle\n        float r = distance(gl_PointCoord, vec2(0.5));\n        if (r > 0.5) discard;\n        \n        gl_FragColor = vec4(vColor, 1.0);\n      }\n    `,\n    transparent: true\n  })\n);\n</code></pre>\n<h2>How It Works</h2>\n<ol>\n<li>Audio is captured from either a microphone input or an audio file</li>\n<li>The Web Audio API analyzes the audio frequencies in real-time</li>\n<li>These frequencies are passed to the shader as uniforms</li>\n<li>Each particle is assigned to a specific frequency band</li>\n<li>The particles move and change color based on their frequency's amplitude</li>\n<li>Mouse position is tracked and influences the particles' behavior</li>\n</ol>\n<h2>Challenges</h2>\n<p>The main challenge was optimizing the performance to handle a large number of particles. This was addressed by:</p>\n<ol>\n<li>Using instanced rendering with buffer geometries</li>\n<li>Implementing an octree for efficient mouse interaction</li>\n<li>Limiting expensive calculations to the GPU via custom shaders</li>\n<li>Applying level-of-detail techniques based on viewport size</li>\n</ol>"}},"pageContext":{"id":"aba2ba10-caf0-5ff3-98fe-1840f8921da7"}},"staticQueryHashes":["2421966660"],"slicesMap":{}}